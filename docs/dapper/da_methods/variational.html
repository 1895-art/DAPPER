<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>dapper.da_methods.variational API documentation</title>
<meta name="description" content="Variational DA methods (iEnKS, 4D-Var, etc)" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.da_methods.variational</code></h1>
</header>
<section id="section-intro">
<p>Variational DA methods (iEnKS, 4D-Var, etc)</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Variational DA methods (iEnKS, 4D-Var, etc)&#34;&#34;&#34;

from typing import Optional

import numpy as np
import scipy.linalg as sla

from dapper.admin import da_method
from dapper.tools.stoch import randn
from dapper.tools.utils import progbar
from dapper.tools.matrices import CovMat
from dapper.tools.math import center, mean0, svd0, inflate_ens, pad0, tinv
from dapper.da_methods.ensemble import post_process, hyperprior_coeffs, zeta_a


@da_method
class var_method:
    &#34;Declare default variational arguments.&#34;
    Lag: int    = 1
    nIter: int  = 10
    wtol: float = 0


@var_method
class iEnKS:
    &#34;&#34;&#34;Iterative EnKS.

    Special cases: EnRML, ES-MDA, iEnKF, EnKF [Raa19b]_.

    As in [Boc14]_, optimization uses Gauss-Newton.
    See [Boc12]_ for Levenberg-Marquardt.
    If MDA=True, then there&#39;s not really any optimization,
    but rather Gaussian annealing.

    Args:
      upd_a (str):
        Analysis update form (flavour). One of:

        - &#34;Sqrt&#34;   : as in ETKF  , using a deterministic matrix square root transform.
        - &#34;PertObs&#34;: as in EnRML , using stochastic, perturbed-observations.
        - &#34;Order1&#34; : as in DEnKF of [Sak08a]_.

      Lag:
        Length of the DA window (DAW), in multiples of dkObs (i.e. cycles).

        - Lag=1 (default) =&gt; iterative &#34;filter&#34; iEnKF [Sak12]_.
        - Lag=0           =&gt; maximum-likelihood filter [Zup05]_.

      Shift : How far (in cycles) to slide the DAW.
              Fixed at 1 for code simplicity.

      nIter : Maximal num. of iterations used (&gt;=1).
              Supporting nIter==0 requires more code than it&#39;s worth.

      wtol  : Rel. tolerance defining convergence.
              Default: 0 =&gt; always do nIter iterations.
              Recommended: 1e-5.

      MDA   : Use iterations of the &#34;multiple data assimlation&#34; type.

      bundle: Use finite-diff. linearization instead of of least-squares regression.
              Makes the iEnKS very much alike the iterative, extended KF (IEKS).

      xN    : If set, use EnKF_N() pre-inflation. See further documentation there.

    Total number of model simulations (of duration dtObs): N * (nIter*Lag + 1).
    (due to boundary cases: only asymptotically valid)

    References: [Boc12]_, [Boc13]_, [Boc14]_,
    &#34;&#34;&#34;
    upd_a: str
    N: int
    MDA: bool    = False
    step: bool   = False
    bundle: bool = False
    xN: float    = None
    infl: float  = 1.0
    rot: bool    = False

    # NB It&#39;s very difficult to preview what should happen to
    # all of the time indices in all cases of nIter and Lag.
    # =&gt; Any changes to this function must be unit-tested via
    # scripts/test_iEnKS.py.

    # TODO 4:
    # - step length
    # - Implement quasi-static assimilation. Boc notes:
    #   * The &#39;balancing step&#39; is complicated.
    #   * Trouble playing nice with &#39;-N&#39; inflation estimation.

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats, N = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
        R, KObs, N1 = HMM.Obs.noise.C, HMM.t.KObs, N-1
        Rm12 = R.sym_sqrt_inv

        assert Dyn.noise.C == 0, (
            &#34;Q&gt;0 not yet supported.&#34;
            &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

        if self.bundle:
            EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I
        else:
            EPS = 1.0  # prefer using  T=EPS*T, yielding a conditional cloud shape

        # Initial ensemble
        E = X0.sample(N)

        # Loop over DA windows (DAW).
        for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW  = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if 0 &lt;= kObs &lt;= KObs:

                # Init iterations.
                X0, x0 = center(E)    # Decompose ensemble.
                w      = np.zeros(N)  # Control vector for the mean state.
                T      = np.eye(N)    # Anomalies transform matrix.
                Tinv   = np.eye(N)
                # Explicit Tinv [instead of tinv(T)] allows for merging MDA code
                # with iEnKS/EnRML code, and flop savings in &#39;Sqrt&#39; case.

                for iteration in np.arange(self.nIter):
                    # Reconstruct smoothed ensemble.
                    E = x0 + (w + EPS*T)@X0
                    # Forecast.
                    for kCycle in DAW:
                        for k, t, dt in chrono.cycle(kCycle):
                            E = Dyn(E, t-dt, dt)
                    # Observe.
                    Eo = Obs(E, t)

                    # Undo the bundle scaling of ensemble.
                    if EPS != 1.0:
                        E  = inflate_ens(E, 1/EPS)
                        Eo = inflate_ens(Eo, 1/EPS)

                    # Assess forecast stats; store {Xf, T_old} for analysis assessment.
                    if iteration == 0:
                        stats.assess(k, kObs, &#39;f&#39;, E=E)
                        Xf, xf = center(E)
                    T_old = T

                    # Prepare analysis.
                    y      = yy[kObs]           # Get current obs.
                    Y, xo  = center(Eo)         # Get obs {anomalies, mean}.
                    dy     = (y - xo) @ Rm12.T  # Transform obs space.
                    Y      = Y        @ Rm12.T  # Transform obs space.
                    Y0     = Tinv @ Y           # &#34;De-condition&#34; the obs anomalies.
                    V, s, UT = svd0(Y0)         # Decompose Y0.

                    # Set &#34;cov normlzt fctr&#34; za (&#34;effective ensemble size&#34;)
                    # =&gt; pre_infl^2 = (N-1)/za.
                    if self.xN is None:
                        za  = N1
                    else:
                        za  = zeta_a(*hyperprior_coeffs(s, N, self.xN), w)
                    if self.MDA:
                        # inflation (factor: nIter) of the ObsErrCov.
                        za *= self.nIter

                    # Post. cov (approx) of w,
                    # estimated at current iteration, raised to power.
                    def Cowp(expo): return (V * (pad0(s**2, N) + za)**-expo) @ V.T
                    Cow1 = Cowp(1.0)

                    if self.MDA:  # View update as annealing (progressive assimilation).
                        Cow1 = Cow1 @ T  # apply previous update
                        dw = dy @ Y.T @ Cow1
                        if &#39;PertObs&#39; in self.upd_a:  # == &#34;ES-MDA&#34;. By Emerick/Reynolds.
                            D     = mean0(randn(Y.shape)) * np.sqrt(self.nIter)
                            T    -= (Y + D) @ Y.T @ Cow1
                        elif &#39;Sqrt&#39; in self.upd_a:  # == &#34;ETKF-ish&#34;. By Raanes.
                            T     = Cowp(0.5) * np.sqrt(za) @ T
                        elif &#39;Order1&#39; in self.upd_a:  # == &#34;DEnKF-ish&#34;. By Emerick.
                            T    -= 0.5 * Y @ Y.T @ Cow1
                        # Tinv = eye(N) [as initialized] coz MDA does not de-condition.

                    else:  # View update as Gauss-Newton optimzt. of log-posterior.
                        grad  = Y0@dy - w*za                  # Cost function gradient
                        dw    = grad@Cow1                     # Gauss-Newton step
                        # ETKF-ish&#34;. By Bocquet/Sakov.
                        if &#39;Sqrt&#39; in self.upd_a:
                            # Sqrt-transforms
                            T     = Cowp(0.5) * np.sqrt(N1)
                            Tinv  = Cowp(-.5) / np.sqrt(N1)
                            # Tinv saves time [vs tinv(T)] when Nx&lt;N
                        # &#34;EnRML&#34;. By Oliver/Chen/Raanes/Evensen/Stordal.
                        elif &#39;PertObs&#39; in self.upd_a:
                            D     = mean0(randn(Y.shape)) if iteration == 0 else D
                            gradT = -(Y+D)@Y0.T + N1*(np.eye(N) - T)
                            T     = T + gradT@Cow1
                            # Tinv= tinv(T, threshold=N1)  # unstable
                            Tinv  = sla.inv(T+1)           # the +1 is for stability.
                        # &#34;DEnKF-ish&#34;. By Raanes.
                        elif &#39;Order1&#39; in self.upd_a:
                            # Included for completeness; does not make much sense.
                            gradT = -0.5*Y@Y0.T + N1*(np.eye(N) - T)
                            T     = T + gradT@Cow1
                            Tinv  = tinv(T, threshold=N1)

                    w += dw
                    if dw@dw &lt; self.wtol*N:
                        break
                # END loop iteration

                # Assess (analysis) stats.
                # The final_increment is a linearization to
                # (i) avoid re-running the model and
                # (ii) reproduce EnKF in case nIter==1.
                final_increment = (dw+T-T_old)@Xf
                # See docs/snippets/iEnKS_Ea.jpg.
                stats.assess(k, kObs, &#39;a&#39;, E=E+final_increment)
                stats.iters[kObs] = iteration+1
                if self.xN:
                    stats.infl[kObs] = np.sqrt(N1/za)

                # Final (smoothed) estimate of E at [kLag].
                E = x0 + (w+T)@X0
                E = post_process(E, self.infl, self.rot)
            # END assimilation block

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) ensemble from [kLag].
            if -1 &lt;= kLag &lt; KObs:
                if kLag &gt;= 0:
                    stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, E=E)
                for k, t, dt in chrono.cycle(kLag+1):
                    stats.assess(k-1, None, &#39;u&#39;, E=E)
                    E = Dyn(E, t-dt, dt)

        # END loop kObs
        stats.assess(k, KObs, &#39;us&#39;, E=E)


@var_method
class iLEnKS:
    &#34;&#34;&#34;Iterative, Localized EnKS-N. [Boc16]_

    Based on iEnKS() and LETKF() codes,
    which describes the other input arguments.

    - upd_a : - &#39;Sqrt&#39; (i.e. ETKF)
              - &#39;-N&#39; (i.e. EnKF-N)
    &#34;&#34;&#34;
    upd_a: str
    N: int
    loc_rad: float
    taper: str   = &#39;GC&#39;
    xN: float = None
    infl: float = 1.0
    rot: bool  = False

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats, N = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
        R, KObs, N1 = HMM.Obs.noise.C, HMM.t.KObs, N-1
        assert Dyn.noise.C == 0, (
            &#34;Q&gt;0 not yet supported.&#34;
            &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

        # Init DA cycles
        E = X0.sample(N)

        # Loop DA cycles
        for kObs in progbar(np.arange(KObs+1)):
            # Set (shifting) DA Window. Shift is 1.
            DAW_0  = kObs-self.Lag+1
            DAW    = np.arange(max(0, DAW_0), DAW_0+self.Lag)
            DAW_dt = chrono.ttObs[DAW[-1]] - chrono.ttObs[DAW[0]] + chrono.dtObs

            # Get localization setup (at time t)
            state_batches, obs_taperer = Obs.localizer(
                self.loc_rad, &#39;x2y&#39;, chrono.ttObs[kObs], self.taper)
            nBatch = len(state_batches)

            # Store 0th (iteration) estimate as (x0,A0)
            A0, x0  = center(E)
            # Init iterations
            w      = np.tile(np.zeros(N), (nBatch, 1))
            Tinv   = np.tile(np.eye(N), (nBatch, 1, 1))
            T      = np.tile(np.eye(N), (nBatch, 1, 1))

            # Loop iterations
            for iteration in np.arange(self.nIter):

                # Assemble current estimate of E[kObs-Lag]
                for ib, ii in enumerate(state_batches):
                    E[:, ii] = x0[ii] + w[ib]@A0[:, ii] + T[ib]@A0[:, ii]

                # Forecast
                for kDAW in DAW:                           # Loop Lag cycles
                    # Loop dkObs steps (1 cycle)
                    for k, t, dt in chrono.cycle(kDAW):
                        # Forecast 1 dt step (1 dkObs)
                        E = Dyn(E, t-dt, dt)

                if iteration == 0:
                    stats.assess(k, kObs, &#39;f&#39;, E=E)

                # Analysis of y[kObs] (already assim&#39;d [:kObs])
                y    = yy[kObs]
                Y, xo = center(Obs(E, t))
                # Transform obs space
                Y  = Y        @ R.sym_sqrt_inv.T
                dy = (y - xo) @ R.sym_sqrt_inv.T

                # Inflation estimation.
                # Set &#34;effective ensemble size&#34;, za = (N-1)/pre-inflation^2.
                if self.upd_a == &#39;Sqrt&#39;:
                    za = N1  # no inflation
                elif self.upd_a == &#39;-N&#39;:
                    # Careful not to overwrite w,T,Tinv !
                    V, s, UT = svd0(Y)
                    grad   = Y@dy
                    Pw     = (V * (pad0(s**2, N) + N1)**-1.0) @ V.T
                    w_glob = Pw@grad
                    za     = zeta_a(*hyperprior_coeffs(s, N, self.xN), w_glob)
                else:
                    raise KeyError(&#34;upd_a: &#39;&#34; + self.upd_a + &#34;&#39; not matched.&#34;)

                for ib, ii in enumerate(state_batches):
                    # Shift indices (to adjust for time difference)
                    ii_kObs = Obs.loc_shift(ii, DAW_dt)
                    # Localize
                    jj, tapering = obs_taperer(ii_kObs)
                    if len(jj) == 0:
                        continue
                    Y_jj   = Y[:, jj] * np.sqrt(tapering)
                    dy_jj  = dy[jj]  * np.sqrt(tapering)

                    # &#34;Uncondition&#34; the observation anomalies
                    # (and yet this linearization of Obs.mod improves with iterations)
                    Y_jj     = Tinv[ib] @ Y_jj
                    # Prepare analysis: do SVD
                    V, s, UT   = svd0(Y_jj)
                    # Gauss-Newton ingredients
                    grad     = -Y_jj@dy_jj + w[ib]*za
                    Pw       = (V * (pad0(s**2, N) + za)**-1.0) @ V.T
                    # Conditioning for anomalies (discrete linearlizations)
                    T[ib]    = (V * (pad0(s**2, N) + za)**-0.5) @ V.T * np.sqrt(N1)
                    Tinv[ib] = (V * (pad0(s**2, N) + za)**+0.5) @ V.T / np.sqrt(N1)
                    # Gauss-Newton step
                    dw       = Pw@grad
                    w[ib]   -= dw

                # Stopping condition # TODO 2
                # if np.linalg.norm(dw) &lt; N*1e-4:
                    # break

            # Analysis &#39;a&#39; stats for E[kObs].
            stats.assess(k, kObs, &#39;a&#39;, E=E)
            stats.trHK[kObs] = np.trace(Y.T @ Pw @ Y)/HMM.Ny
            stats.infl[kObs] = np.sqrt(N1/za)
            stats.iters[kObs] = iteration+1

            # Final (smoothed) estimate of E[kObs-Lag]
            for ib, ii in enumerate(state_batches):
                E[:, ii] = x0[ii] + w[ib]@A0[:, ii] + T[ib]@A0[:, ii]

            E = post_process(E, self.infl, self.rot)

            # Forecast smoothed ensemble by shift (1*dkObs)
            if DAW_0 &gt;= 0:
                for k, t, dt in chrono.cycle(DAW_0):
                    stats.assess(k-1, None, &#39;u&#39;, E=E)
                    E = Dyn(E, t-dt, dt)

        # Assess the last (Lag-1) obs ranges
        for kDAW in np.arange(DAW[0]+1, KObs+1):
            for k, t, dt in chrono.cycle(kDAW):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = Dyn(E, t-dt, dt)
        stats.assess(chrono.K, None, &#39;u&#39;, E=E)


@var_method
class Var4D:
    &#34;&#34;&#34;4D-Var.

    Cycling scheme is same as in iEnKS (i.e. the shift is always 1*kObs).

    This implementation does NOT do gradient decent (nor quasi-Newton)
    in an inner loop, with simplified models.
    Instead, each (outer) iteration is computed
    non-iteratively as a Gauss-Newton step.
    Thus, since the full (approximate) Hessian is formed,
    there is no benefit to the adjoint trick (back-propagation).
    =&gt; This implementation is not suited for big systems.

    Incremental formulation is used, so the formulae look like the ones in iEnKS.
    &#34;&#34;&#34;
    B: Optional[np.ndarray] = None
    xB: float                = 1.0

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
        R, KObs = HMM.Obs.noise.C, HMM.t.KObs
        Rm12 = R.sym_sqrt_inv
        Nx = Dyn.M

        # Set background covariance. Note that it is static (compare to iEnKS).
        if self.B in (None, &#39;clim&#39;):
            # Use climatological cov, ...
            B = np.cov(xx.T)  # ... estimated from truth
        elif self.B == &#39;eye&#39;:
            B = np.eye(Nx)
        else:
            B = self.B
        B *= self.xB
        B12 = CovMat(B).sym_sqrt

        # Init
        x = X0.mu
        stats.assess(0, mu=x, Cov=B)

        # Loop over DA windows (DAW).
        for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if 0 &lt;= kObs &lt;= KObs:

                # Init iterations.
                w   = np.zeros(Nx)  # Control vector for the mean state.
                x0  = x.copy()     # Increment reference.

                for iteration in np.arange(self.nIter):
                    # Reconstruct smoothed state.
                    x = x0 + B12@w
                    X = B12  # Aggregate composite TLMs onto B12
                    # Forecast.
                    for kCycle in DAW:
                        for k, t, dt in chrono.cycle(kCycle):
                            X = Dyn.linear(x, t-dt, dt) @ X
                            x = Dyn(x, t-dt, dt)

                    # Assess forecast stats
                    if iteration == 0:
                        stats.assess(k, kObs, &#39;f&#39;, mu=x, Cov=X@X.T)

                    # Observe.
                    Y  = Obs.linear(x, t) @ X
                    xo = Obs(x, t)

                    # Analysis prep.
                    y      = yy[kObs]          # Get current obs.
                    dy     = Rm12 @ (y - xo)   # Transform obs space.
                    Y      = Rm12 @ Y          # Transform obs space.
                    V, s, UT = svd0(Y.T)         # Decomp for lin-alg update comps.

                    # Post. cov (approx) of w,
                    # estimated at current iteration, raised to power.
                    Cow1 = (V * (pad0(s**2, Nx) + 1)**-1.0) @ V.T

                    # Compute analysis update.
                    grad = Y.T@dy - w          # Cost function gradient
                    dw   = Cow1@grad           # Gauss-Newton step
                    w   += dw                  # Step

                    if dw@dw &lt; self.wtol*Nx:
                        break
                # END loop iteration

                # Assess (analysis) stats.
                final_increment = X@dw
                stats.assess(k,   kObs, &#39;a&#39;, mu=x+final_increment, Cov=X@Cow1@X.T)
                stats.iters[kObs] = iteration+1

                # Final (smoothed) estimate at [kLag].
                x = x0 + B12@w
                X = B12
            # END assimilation block

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) state from [kLag].
            if -1 &lt;= kLag &lt; KObs:
                if kLag &gt;= 0:
                    stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, mu=x, Cov=X@Cow1@X.T)
                for k, t, dt in chrono.cycle(kLag+1):
                    stats.assess(k-1, None, &#39;u&#39;, mu=x, Cov=Y@Y.T)
                    X = Dyn.linear(x, t-dt, dt) @ X
                    x = Dyn(x, t-dt, dt)

        # END loop kObs
        stats.assess(k, KObs, &#39;us&#39;, mu=x, Cov=X@Cow1@X.T)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.da_methods.variational.iEnKS"><code class="flex name class">
<span>class <span class="ident">iEnKS</span></span>
<span>(</span><span>upd_a: str, N: int, MDA: bool = False, step: bool = False, bundle: bool = False, xN: float = None, infl: float = 1.0, rot: bool = False, Lag: int = 1, nIter: int = 10, wtol: float = 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Iterative EnKS.</p>
<p>Special cases: EnRML, ES-MDA, iEnKF, EnKF [Raa19b]_.</p>
<p>As in [Boc14]<em>, optimization uses Gauss-Newton.
See [Boc12]</em> for Levenberg-Marquardt.
If MDA=True, then there's not really any optimization,
but rather Gaussian annealing.</p>
<h2 id="args">Args</h2>
<p>upd_a (str):
Analysis update form (flavour). One of:</p>
<ul>
<li>"Sqrt"
: as in ETKF
, using a deterministic matrix square root transform.</li>
<li>"PertObs": as in EnRML , using stochastic, perturbed-observations.</li>
<li>"Order1" : as in DEnKF of [Sak08a]_.</li>
</ul>
<p>Lag:
Length of the DA window (DAW), in multiples of dkObs (i.e. cycles).</p>
<ul>
<li>Lag=1 (default) =&gt; iterative "filter" iEnKF [Sak12]_.</li>
<li>Lag=0
=&gt; maximum-likelihood filter [Zup05]_.</li>
</ul>
<p>Shift : How far (in cycles) to slide the DAW.
Fixed at 1 for code simplicity.</p>
<p>nIter : Maximal num. of iterations used (&gt;=1).
Supporting nIter==0 requires more code than it's worth.</p>
<p>wtol
: Rel. tolerance defining convergence.
Default: 0 =&gt; always do nIter iterations.
Recommended: 1e-5.</p>
<p>MDA
: Use iterations of the "multiple data assimlation" type.</p>
<dl>
<dt><strong><code>bundle</code></strong></dt>
<dd>Use finite-diff. linearization instead of of least-squares regression.
Makes the iEnKS very much alike the iterative, extended KF (IEKS).</dd>
</dl>
<p>xN
: If set, use EnKF_N() pre-inflation. See further documentation there.
Total number of model simulations (of duration dtObs): N * (nIter*Lag + 1).
(due to boundary cases: only asymptotically valid)</p>
<p>References: [Boc12]<em>, [Boc13]</em>, [Boc14]_,</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class iEnKS:
    &#34;&#34;&#34;Iterative EnKS.

    Special cases: EnRML, ES-MDA, iEnKF, EnKF [Raa19b]_.

    As in [Boc14]_, optimization uses Gauss-Newton.
    See [Boc12]_ for Levenberg-Marquardt.
    If MDA=True, then there&#39;s not really any optimization,
    but rather Gaussian annealing.

    Args:
      upd_a (str):
        Analysis update form (flavour). One of:

        - &#34;Sqrt&#34;   : as in ETKF  , using a deterministic matrix square root transform.
        - &#34;PertObs&#34;: as in EnRML , using stochastic, perturbed-observations.
        - &#34;Order1&#34; : as in DEnKF of [Sak08a]_.

      Lag:
        Length of the DA window (DAW), in multiples of dkObs (i.e. cycles).

        - Lag=1 (default) =&gt; iterative &#34;filter&#34; iEnKF [Sak12]_.
        - Lag=0           =&gt; maximum-likelihood filter [Zup05]_.

      Shift : How far (in cycles) to slide the DAW.
              Fixed at 1 for code simplicity.

      nIter : Maximal num. of iterations used (&gt;=1).
              Supporting nIter==0 requires more code than it&#39;s worth.

      wtol  : Rel. tolerance defining convergence.
              Default: 0 =&gt; always do nIter iterations.
              Recommended: 1e-5.

      MDA   : Use iterations of the &#34;multiple data assimlation&#34; type.

      bundle: Use finite-diff. linearization instead of of least-squares regression.
              Makes the iEnKS very much alike the iterative, extended KF (IEKS).

      xN    : If set, use EnKF_N() pre-inflation. See further documentation there.

    Total number of model simulations (of duration dtObs): N * (nIter*Lag + 1).
    (due to boundary cases: only asymptotically valid)

    References: [Boc12]_, [Boc13]_, [Boc14]_,
    &#34;&#34;&#34;
    upd_a: str
    N: int
    MDA: bool    = False
    step: bool   = False
    bundle: bool = False
    xN: float    = None
    infl: float  = 1.0
    rot: bool    = False

    # NB It&#39;s very difficult to preview what should happen to
    # all of the time indices in all cases of nIter and Lag.
    # =&gt; Any changes to this function must be unit-tested via
    # scripts/test_iEnKS.py.

    # TODO 4:
    # - step length
    # - Implement quasi-static assimilation. Boc notes:
    #   * The &#39;balancing step&#39; is complicated.
    #   * Trouble playing nice with &#39;-N&#39; inflation estimation.

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats, N = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
        R, KObs, N1 = HMM.Obs.noise.C, HMM.t.KObs, N-1
        Rm12 = R.sym_sqrt_inv

        assert Dyn.noise.C == 0, (
            &#34;Q&gt;0 not yet supported.&#34;
            &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

        if self.bundle:
            EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I
        else:
            EPS = 1.0  # prefer using  T=EPS*T, yielding a conditional cloud shape

        # Initial ensemble
        E = X0.sample(N)

        # Loop over DA windows (DAW).
        for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW  = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if 0 &lt;= kObs &lt;= KObs:

                # Init iterations.
                X0, x0 = center(E)    # Decompose ensemble.
                w      = np.zeros(N)  # Control vector for the mean state.
                T      = np.eye(N)    # Anomalies transform matrix.
                Tinv   = np.eye(N)
                # Explicit Tinv [instead of tinv(T)] allows for merging MDA code
                # with iEnKS/EnRML code, and flop savings in &#39;Sqrt&#39; case.

                for iteration in np.arange(self.nIter):
                    # Reconstruct smoothed ensemble.
                    E = x0 + (w + EPS*T)@X0
                    # Forecast.
                    for kCycle in DAW:
                        for k, t, dt in chrono.cycle(kCycle):
                            E = Dyn(E, t-dt, dt)
                    # Observe.
                    Eo = Obs(E, t)

                    # Undo the bundle scaling of ensemble.
                    if EPS != 1.0:
                        E  = inflate_ens(E, 1/EPS)
                        Eo = inflate_ens(Eo, 1/EPS)

                    # Assess forecast stats; store {Xf, T_old} for analysis assessment.
                    if iteration == 0:
                        stats.assess(k, kObs, &#39;f&#39;, E=E)
                        Xf, xf = center(E)
                    T_old = T

                    # Prepare analysis.
                    y      = yy[kObs]           # Get current obs.
                    Y, xo  = center(Eo)         # Get obs {anomalies, mean}.
                    dy     = (y - xo) @ Rm12.T  # Transform obs space.
                    Y      = Y        @ Rm12.T  # Transform obs space.
                    Y0     = Tinv @ Y           # &#34;De-condition&#34; the obs anomalies.
                    V, s, UT = svd0(Y0)         # Decompose Y0.

                    # Set &#34;cov normlzt fctr&#34; za (&#34;effective ensemble size&#34;)
                    # =&gt; pre_infl^2 = (N-1)/za.
                    if self.xN is None:
                        za  = N1
                    else:
                        za  = zeta_a(*hyperprior_coeffs(s, N, self.xN), w)
                    if self.MDA:
                        # inflation (factor: nIter) of the ObsErrCov.
                        za *= self.nIter

                    # Post. cov (approx) of w,
                    # estimated at current iteration, raised to power.
                    def Cowp(expo): return (V * (pad0(s**2, N) + za)**-expo) @ V.T
                    Cow1 = Cowp(1.0)

                    if self.MDA:  # View update as annealing (progressive assimilation).
                        Cow1 = Cow1 @ T  # apply previous update
                        dw = dy @ Y.T @ Cow1
                        if &#39;PertObs&#39; in self.upd_a:  # == &#34;ES-MDA&#34;. By Emerick/Reynolds.
                            D     = mean0(randn(Y.shape)) * np.sqrt(self.nIter)
                            T    -= (Y + D) @ Y.T @ Cow1
                        elif &#39;Sqrt&#39; in self.upd_a:  # == &#34;ETKF-ish&#34;. By Raanes.
                            T     = Cowp(0.5) * np.sqrt(za) @ T
                        elif &#39;Order1&#39; in self.upd_a:  # == &#34;DEnKF-ish&#34;. By Emerick.
                            T    -= 0.5 * Y @ Y.T @ Cow1
                        # Tinv = eye(N) [as initialized] coz MDA does not de-condition.

                    else:  # View update as Gauss-Newton optimzt. of log-posterior.
                        grad  = Y0@dy - w*za                  # Cost function gradient
                        dw    = grad@Cow1                     # Gauss-Newton step
                        # ETKF-ish&#34;. By Bocquet/Sakov.
                        if &#39;Sqrt&#39; in self.upd_a:
                            # Sqrt-transforms
                            T     = Cowp(0.5) * np.sqrt(N1)
                            Tinv  = Cowp(-.5) / np.sqrt(N1)
                            # Tinv saves time [vs tinv(T)] when Nx&lt;N
                        # &#34;EnRML&#34;. By Oliver/Chen/Raanes/Evensen/Stordal.
                        elif &#39;PertObs&#39; in self.upd_a:
                            D     = mean0(randn(Y.shape)) if iteration == 0 else D
                            gradT = -(Y+D)@Y0.T + N1*(np.eye(N) - T)
                            T     = T + gradT@Cow1
                            # Tinv= tinv(T, threshold=N1)  # unstable
                            Tinv  = sla.inv(T+1)           # the +1 is for stability.
                        # &#34;DEnKF-ish&#34;. By Raanes.
                        elif &#39;Order1&#39; in self.upd_a:
                            # Included for completeness; does not make much sense.
                            gradT = -0.5*Y@Y0.T + N1*(np.eye(N) - T)
                            T     = T + gradT@Cow1
                            Tinv  = tinv(T, threshold=N1)

                    w += dw
                    if dw@dw &lt; self.wtol*N:
                        break
                # END loop iteration

                # Assess (analysis) stats.
                # The final_increment is a linearization to
                # (i) avoid re-running the model and
                # (ii) reproduce EnKF in case nIter==1.
                final_increment = (dw+T-T_old)@Xf
                # See docs/snippets/iEnKS_Ea.jpg.
                stats.assess(k, kObs, &#39;a&#39;, E=E+final_increment)
                stats.iters[kObs] = iteration+1
                if self.xN:
                    stats.infl[kObs] = np.sqrt(N1/za)

                # Final (smoothed) estimate of E at [kLag].
                E = x0 + (w+T)@X0
                E = post_process(E, self.infl, self.rot)
            # END assimilation block

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) ensemble from [kLag].
            if -1 &lt;= kLag &lt; KObs:
                if kLag &gt;= 0:
                    stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, E=E)
                for k, t, dt in chrono.cycle(kLag+1):
                    stats.assess(k-1, None, &#39;u&#39;, E=E)
                    E = Dyn(E, t-dt, dt)

        # END loop kObs
        stats.assess(k, KObs, &#39;us&#39;, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.variational.iEnKS.upd_a"><code class="name">var <span class="ident">upd_a</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.N"><code class="name">var <span class="ident">N</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.MDA"><code class="name">var <span class="ident">MDA</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.step"><code class="name">var <span class="ident">step</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.bundle"><code class="name">var <span class="ident">bundle</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.xN"><code class="name">var <span class="ident">xN</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.infl"><code class="name">var <span class="ident">infl</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.rot"><code class="name">var <span class="ident">rot</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.Lag"><code class="name">var <span class="ident">Lag</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.nIter"><code class="name">var <span class="ident">nIter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.wtol"><code class="name">var <span class="ident">wtol</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iEnKS.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.variational.iEnKS.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats, N = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
    R, KObs, N1 = HMM.Obs.noise.C, HMM.t.KObs, N-1
    Rm12 = R.sym_sqrt_inv

    assert Dyn.noise.C == 0, (
        &#34;Q&gt;0 not yet supported.&#34;
        &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

    if self.bundle:
        EPS = 1e-4  # Sakov/Boc use T=EPS*eye(N), with EPS=1e-4, but I
    else:
        EPS = 1.0  # prefer using  T=EPS*T, yielding a conditional cloud shape

    # Initial ensemble
    E = X0.sample(N)

    # Loop over DA windows (DAW).
    for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
        kLag = kObs-self.Lag
        DAW  = range(max(0, kLag+1), min(kObs, KObs) + 1)

        # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
        if 0 &lt;= kObs &lt;= KObs:

            # Init iterations.
            X0, x0 = center(E)    # Decompose ensemble.
            w      = np.zeros(N)  # Control vector for the mean state.
            T      = np.eye(N)    # Anomalies transform matrix.
            Tinv   = np.eye(N)
            # Explicit Tinv [instead of tinv(T)] allows for merging MDA code
            # with iEnKS/EnRML code, and flop savings in &#39;Sqrt&#39; case.

            for iteration in np.arange(self.nIter):
                # Reconstruct smoothed ensemble.
                E = x0 + (w + EPS*T)@X0
                # Forecast.
                for kCycle in DAW:
                    for k, t, dt in chrono.cycle(kCycle):
                        E = Dyn(E, t-dt, dt)
                # Observe.
                Eo = Obs(E, t)

                # Undo the bundle scaling of ensemble.
                if EPS != 1.0:
                    E  = inflate_ens(E, 1/EPS)
                    Eo = inflate_ens(Eo, 1/EPS)

                # Assess forecast stats; store {Xf, T_old} for analysis assessment.
                if iteration == 0:
                    stats.assess(k, kObs, &#39;f&#39;, E=E)
                    Xf, xf = center(E)
                T_old = T

                # Prepare analysis.
                y      = yy[kObs]           # Get current obs.
                Y, xo  = center(Eo)         # Get obs {anomalies, mean}.
                dy     = (y - xo) @ Rm12.T  # Transform obs space.
                Y      = Y        @ Rm12.T  # Transform obs space.
                Y0     = Tinv @ Y           # &#34;De-condition&#34; the obs anomalies.
                V, s, UT = svd0(Y0)         # Decompose Y0.

                # Set &#34;cov normlzt fctr&#34; za (&#34;effective ensemble size&#34;)
                # =&gt; pre_infl^2 = (N-1)/za.
                if self.xN is None:
                    za  = N1
                else:
                    za  = zeta_a(*hyperprior_coeffs(s, N, self.xN), w)
                if self.MDA:
                    # inflation (factor: nIter) of the ObsErrCov.
                    za *= self.nIter

                # Post. cov (approx) of w,
                # estimated at current iteration, raised to power.
                def Cowp(expo): return (V * (pad0(s**2, N) + za)**-expo) @ V.T
                Cow1 = Cowp(1.0)

                if self.MDA:  # View update as annealing (progressive assimilation).
                    Cow1 = Cow1 @ T  # apply previous update
                    dw = dy @ Y.T @ Cow1
                    if &#39;PertObs&#39; in self.upd_a:  # == &#34;ES-MDA&#34;. By Emerick/Reynolds.
                        D     = mean0(randn(Y.shape)) * np.sqrt(self.nIter)
                        T    -= (Y + D) @ Y.T @ Cow1
                    elif &#39;Sqrt&#39; in self.upd_a:  # == &#34;ETKF-ish&#34;. By Raanes.
                        T     = Cowp(0.5) * np.sqrt(za) @ T
                    elif &#39;Order1&#39; in self.upd_a:  # == &#34;DEnKF-ish&#34;. By Emerick.
                        T    -= 0.5 * Y @ Y.T @ Cow1
                    # Tinv = eye(N) [as initialized] coz MDA does not de-condition.

                else:  # View update as Gauss-Newton optimzt. of log-posterior.
                    grad  = Y0@dy - w*za                  # Cost function gradient
                    dw    = grad@Cow1                     # Gauss-Newton step
                    # ETKF-ish&#34;. By Bocquet/Sakov.
                    if &#39;Sqrt&#39; in self.upd_a:
                        # Sqrt-transforms
                        T     = Cowp(0.5) * np.sqrt(N1)
                        Tinv  = Cowp(-.5) / np.sqrt(N1)
                        # Tinv saves time [vs tinv(T)] when Nx&lt;N
                    # &#34;EnRML&#34;. By Oliver/Chen/Raanes/Evensen/Stordal.
                    elif &#39;PertObs&#39; in self.upd_a:
                        D     = mean0(randn(Y.shape)) if iteration == 0 else D
                        gradT = -(Y+D)@Y0.T + N1*(np.eye(N) - T)
                        T     = T + gradT@Cow1
                        # Tinv= tinv(T, threshold=N1)  # unstable
                        Tinv  = sla.inv(T+1)           # the +1 is for stability.
                    # &#34;DEnKF-ish&#34;. By Raanes.
                    elif &#39;Order1&#39; in self.upd_a:
                        # Included for completeness; does not make much sense.
                        gradT = -0.5*Y@Y0.T + N1*(np.eye(N) - T)
                        T     = T + gradT@Cow1
                        Tinv  = tinv(T, threshold=N1)

                w += dw
                if dw@dw &lt; self.wtol*N:
                    break
            # END loop iteration

            # Assess (analysis) stats.
            # The final_increment is a linearization to
            # (i) avoid re-running the model and
            # (ii) reproduce EnKF in case nIter==1.
            final_increment = (dw+T-T_old)@Xf
            # See docs/snippets/iEnKS_Ea.jpg.
            stats.assess(k, kObs, &#39;a&#39;, E=E+final_increment)
            stats.iters[kObs] = iteration+1
            if self.xN:
                stats.infl[kObs] = np.sqrt(N1/za)

            # Final (smoothed) estimate of E at [kLag].
            E = x0 + (w+T)@X0
            E = post_process(E, self.infl, self.rot)
        # END assimilation block

        # Slide/shift DAW by propagating smoothed (&#39;s&#39;) ensemble from [kLag].
        if -1 &lt;= kLag &lt; KObs:
            if kLag &gt;= 0:
                stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, E=E)
            for k, t, dt in chrono.cycle(kLag+1):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = Dyn(E, t-dt, dt)

    # END loop kObs
    stats.assess(k, KObs, &#39;us&#39;, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS"><code class="flex name class">
<span>class <span class="ident">iLEnKS</span></span>
<span>(</span><span>upd_a: str, N: int, loc_rad: float, taper: str = 'GC', xN: float = None, infl: float = 1.0, rot: bool = False, Lag: int = 1, nIter: int = 10, wtol: float = 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Iterative, Localized EnKS-N. [Boc16]_</p>
<p>Based on iEnKS() and LETKF() codes,
which describes the other input arguments.</p>
<ul>
<li>upd_a : - 'Sqrt' (i.e. ETKF)
- '-N' (i.e. EnKF-N)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class iLEnKS:
    &#34;&#34;&#34;Iterative, Localized EnKS-N. [Boc16]_

    Based on iEnKS() and LETKF() codes,
    which describes the other input arguments.

    - upd_a : - &#39;Sqrt&#39; (i.e. ETKF)
              - &#39;-N&#39; (i.e. EnKF-N)
    &#34;&#34;&#34;
    upd_a: str
    N: int
    loc_rad: float
    taper: str   = &#39;GC&#39;
    xN: float = None
    infl: float = 1.0
    rot: bool  = False

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats, N = \
            HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
        R, KObs, N1 = HMM.Obs.noise.C, HMM.t.KObs, N-1
        assert Dyn.noise.C == 0, (
            &#34;Q&gt;0 not yet supported.&#34;
            &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

        # Init DA cycles
        E = X0.sample(N)

        # Loop DA cycles
        for kObs in progbar(np.arange(KObs+1)):
            # Set (shifting) DA Window. Shift is 1.
            DAW_0  = kObs-self.Lag+1
            DAW    = np.arange(max(0, DAW_0), DAW_0+self.Lag)
            DAW_dt = chrono.ttObs[DAW[-1]] - chrono.ttObs[DAW[0]] + chrono.dtObs

            # Get localization setup (at time t)
            state_batches, obs_taperer = Obs.localizer(
                self.loc_rad, &#39;x2y&#39;, chrono.ttObs[kObs], self.taper)
            nBatch = len(state_batches)

            # Store 0th (iteration) estimate as (x0,A0)
            A0, x0  = center(E)
            # Init iterations
            w      = np.tile(np.zeros(N), (nBatch, 1))
            Tinv   = np.tile(np.eye(N), (nBatch, 1, 1))
            T      = np.tile(np.eye(N), (nBatch, 1, 1))

            # Loop iterations
            for iteration in np.arange(self.nIter):

                # Assemble current estimate of E[kObs-Lag]
                for ib, ii in enumerate(state_batches):
                    E[:, ii] = x0[ii] + w[ib]@A0[:, ii] + T[ib]@A0[:, ii]

                # Forecast
                for kDAW in DAW:                           # Loop Lag cycles
                    # Loop dkObs steps (1 cycle)
                    for k, t, dt in chrono.cycle(kDAW):
                        # Forecast 1 dt step (1 dkObs)
                        E = Dyn(E, t-dt, dt)

                if iteration == 0:
                    stats.assess(k, kObs, &#39;f&#39;, E=E)

                # Analysis of y[kObs] (already assim&#39;d [:kObs])
                y    = yy[kObs]
                Y, xo = center(Obs(E, t))
                # Transform obs space
                Y  = Y        @ R.sym_sqrt_inv.T
                dy = (y - xo) @ R.sym_sqrt_inv.T

                # Inflation estimation.
                # Set &#34;effective ensemble size&#34;, za = (N-1)/pre-inflation^2.
                if self.upd_a == &#39;Sqrt&#39;:
                    za = N1  # no inflation
                elif self.upd_a == &#39;-N&#39;:
                    # Careful not to overwrite w,T,Tinv !
                    V, s, UT = svd0(Y)
                    grad   = Y@dy
                    Pw     = (V * (pad0(s**2, N) + N1)**-1.0) @ V.T
                    w_glob = Pw@grad
                    za     = zeta_a(*hyperprior_coeffs(s, N, self.xN), w_glob)
                else:
                    raise KeyError(&#34;upd_a: &#39;&#34; + self.upd_a + &#34;&#39; not matched.&#34;)

                for ib, ii in enumerate(state_batches):
                    # Shift indices (to adjust for time difference)
                    ii_kObs = Obs.loc_shift(ii, DAW_dt)
                    # Localize
                    jj, tapering = obs_taperer(ii_kObs)
                    if len(jj) == 0:
                        continue
                    Y_jj   = Y[:, jj] * np.sqrt(tapering)
                    dy_jj  = dy[jj]  * np.sqrt(tapering)

                    # &#34;Uncondition&#34; the observation anomalies
                    # (and yet this linearization of Obs.mod improves with iterations)
                    Y_jj     = Tinv[ib] @ Y_jj
                    # Prepare analysis: do SVD
                    V, s, UT   = svd0(Y_jj)
                    # Gauss-Newton ingredients
                    grad     = -Y_jj@dy_jj + w[ib]*za
                    Pw       = (V * (pad0(s**2, N) + za)**-1.0) @ V.T
                    # Conditioning for anomalies (discrete linearlizations)
                    T[ib]    = (V * (pad0(s**2, N) + za)**-0.5) @ V.T * np.sqrt(N1)
                    Tinv[ib] = (V * (pad0(s**2, N) + za)**+0.5) @ V.T / np.sqrt(N1)
                    # Gauss-Newton step
                    dw       = Pw@grad
                    w[ib]   -= dw

                # Stopping condition # TODO 2
                # if np.linalg.norm(dw) &lt; N*1e-4:
                    # break

            # Analysis &#39;a&#39; stats for E[kObs].
            stats.assess(k, kObs, &#39;a&#39;, E=E)
            stats.trHK[kObs] = np.trace(Y.T @ Pw @ Y)/HMM.Ny
            stats.infl[kObs] = np.sqrt(N1/za)
            stats.iters[kObs] = iteration+1

            # Final (smoothed) estimate of E[kObs-Lag]
            for ib, ii in enumerate(state_batches):
                E[:, ii] = x0[ii] + w[ib]@A0[:, ii] + T[ib]@A0[:, ii]

            E = post_process(E, self.infl, self.rot)

            # Forecast smoothed ensemble by shift (1*dkObs)
            if DAW_0 &gt;= 0:
                for k, t, dt in chrono.cycle(DAW_0):
                    stats.assess(k-1, None, &#39;u&#39;, E=E)
                    E = Dyn(E, t-dt, dt)

        # Assess the last (Lag-1) obs ranges
        for kDAW in np.arange(DAW[0]+1, KObs+1):
            for k, t, dt in chrono.cycle(kDAW):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = Dyn(E, t-dt, dt)
        stats.assess(chrono.K, None, &#39;u&#39;, E=E)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.variational.iLEnKS.upd_a"><code class="name">var <span class="ident">upd_a</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.N"><code class="name">var <span class="ident">N</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.loc_rad"><code class="name">var <span class="ident">loc_rad</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.taper"><code class="name">var <span class="ident">taper</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.xN"><code class="name">var <span class="ident">xN</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.infl"><code class="name">var <span class="ident">infl</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.rot"><code class="name">var <span class="ident">rot</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.Lag"><code class="name">var <span class="ident">Lag</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.nIter"><code class="name">var <span class="ident">nIter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.wtol"><code class="name">var <span class="ident">wtol</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.iLEnKS.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.variational.iLEnKS.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats, N = \
        HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats, self.N
    R, KObs, N1 = HMM.Obs.noise.C, HMM.t.KObs, N-1
    assert Dyn.noise.C == 0, (
        &#34;Q&gt;0 not yet supported.&#34;
        &#34; See Sakov et al 2017: &#39;An iEnKF with mod. error&#39;&#34;)

    # Init DA cycles
    E = X0.sample(N)

    # Loop DA cycles
    for kObs in progbar(np.arange(KObs+1)):
        # Set (shifting) DA Window. Shift is 1.
        DAW_0  = kObs-self.Lag+1
        DAW    = np.arange(max(0, DAW_0), DAW_0+self.Lag)
        DAW_dt = chrono.ttObs[DAW[-1]] - chrono.ttObs[DAW[0]] + chrono.dtObs

        # Get localization setup (at time t)
        state_batches, obs_taperer = Obs.localizer(
            self.loc_rad, &#39;x2y&#39;, chrono.ttObs[kObs], self.taper)
        nBatch = len(state_batches)

        # Store 0th (iteration) estimate as (x0,A0)
        A0, x0  = center(E)
        # Init iterations
        w      = np.tile(np.zeros(N), (nBatch, 1))
        Tinv   = np.tile(np.eye(N), (nBatch, 1, 1))
        T      = np.tile(np.eye(N), (nBatch, 1, 1))

        # Loop iterations
        for iteration in np.arange(self.nIter):

            # Assemble current estimate of E[kObs-Lag]
            for ib, ii in enumerate(state_batches):
                E[:, ii] = x0[ii] + w[ib]@A0[:, ii] + T[ib]@A0[:, ii]

            # Forecast
            for kDAW in DAW:                           # Loop Lag cycles
                # Loop dkObs steps (1 cycle)
                for k, t, dt in chrono.cycle(kDAW):
                    # Forecast 1 dt step (1 dkObs)
                    E = Dyn(E, t-dt, dt)

            if iteration == 0:
                stats.assess(k, kObs, &#39;f&#39;, E=E)

            # Analysis of y[kObs] (already assim&#39;d [:kObs])
            y    = yy[kObs]
            Y, xo = center(Obs(E, t))
            # Transform obs space
            Y  = Y        @ R.sym_sqrt_inv.T
            dy = (y - xo) @ R.sym_sqrt_inv.T

            # Inflation estimation.
            # Set &#34;effective ensemble size&#34;, za = (N-1)/pre-inflation^2.
            if self.upd_a == &#39;Sqrt&#39;:
                za = N1  # no inflation
            elif self.upd_a == &#39;-N&#39;:
                # Careful not to overwrite w,T,Tinv !
                V, s, UT = svd0(Y)
                grad   = Y@dy
                Pw     = (V * (pad0(s**2, N) + N1)**-1.0) @ V.T
                w_glob = Pw@grad
                za     = zeta_a(*hyperprior_coeffs(s, N, self.xN), w_glob)
            else:
                raise KeyError(&#34;upd_a: &#39;&#34; + self.upd_a + &#34;&#39; not matched.&#34;)

            for ib, ii in enumerate(state_batches):
                # Shift indices (to adjust for time difference)
                ii_kObs = Obs.loc_shift(ii, DAW_dt)
                # Localize
                jj, tapering = obs_taperer(ii_kObs)
                if len(jj) == 0:
                    continue
                Y_jj   = Y[:, jj] * np.sqrt(tapering)
                dy_jj  = dy[jj]  * np.sqrt(tapering)

                # &#34;Uncondition&#34; the observation anomalies
                # (and yet this linearization of Obs.mod improves with iterations)
                Y_jj     = Tinv[ib] @ Y_jj
                # Prepare analysis: do SVD
                V, s, UT   = svd0(Y_jj)
                # Gauss-Newton ingredients
                grad     = -Y_jj@dy_jj + w[ib]*za
                Pw       = (V * (pad0(s**2, N) + za)**-1.0) @ V.T
                # Conditioning for anomalies (discrete linearlizations)
                T[ib]    = (V * (pad0(s**2, N) + za)**-0.5) @ V.T * np.sqrt(N1)
                Tinv[ib] = (V * (pad0(s**2, N) + za)**+0.5) @ V.T / np.sqrt(N1)
                # Gauss-Newton step
                dw       = Pw@grad
                w[ib]   -= dw

            # Stopping condition # TODO 2
            # if np.linalg.norm(dw) &lt; N*1e-4:
                # break

        # Analysis &#39;a&#39; stats for E[kObs].
        stats.assess(k, kObs, &#39;a&#39;, E=E)
        stats.trHK[kObs] = np.trace(Y.T @ Pw @ Y)/HMM.Ny
        stats.infl[kObs] = np.sqrt(N1/za)
        stats.iters[kObs] = iteration+1

        # Final (smoothed) estimate of E[kObs-Lag]
        for ib, ii in enumerate(state_batches):
            E[:, ii] = x0[ii] + w[ib]@A0[:, ii] + T[ib]@A0[:, ii]

        E = post_process(E, self.infl, self.rot)

        # Forecast smoothed ensemble by shift (1*dkObs)
        if DAW_0 &gt;= 0:
            for k, t, dt in chrono.cycle(DAW_0):
                stats.assess(k-1, None, &#39;u&#39;, E=E)
                E = Dyn(E, t-dt, dt)

    # Assess the last (Lag-1) obs ranges
    for kDAW in np.arange(DAW[0]+1, KObs+1):
        for k, t, dt in chrono.cycle(kDAW):
            stats.assess(k-1, None, &#39;u&#39;, E=E)
            E = Dyn(E, t-dt, dt)
    stats.assess(chrono.K, None, &#39;u&#39;, E=E)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.da_methods.variational.Var4D"><code class="flex name class">
<span>class <span class="ident">Var4D</span></span>
<span>(</span><span>B: Union[numpy.ndarray, NoneType] = None, xB: float = 1.0, Lag: int = 1, nIter: int = 10, wtol: float = 0)</span>
</code></dt>
<dd>
<div class="desc"><p>4D-Var.</p>
<p>Cycling scheme is same as in iEnKS (i.e. the shift is always 1*kObs).</p>
<p>This implementation does NOT do gradient decent (nor quasi-Newton)
in an inner loop, with simplified models.
Instead, each (outer) iteration is computed
non-iteratively as a Gauss-Newton step.
Thus, since the full (approximate) Hessian is formed,
there is no benefit to the adjoint trick (back-propagation).
=&gt; This implementation is not suited for big systems.</p>
<p>Incremental formulation is used, so the formulae look like the ones in iEnKS.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Var4D:
    &#34;&#34;&#34;4D-Var.

    Cycling scheme is same as in iEnKS (i.e. the shift is always 1*kObs).

    This implementation does NOT do gradient decent (nor quasi-Newton)
    in an inner loop, with simplified models.
    Instead, each (outer) iteration is computed
    non-iteratively as a Gauss-Newton step.
    Thus, since the full (approximate) Hessian is formed,
    there is no benefit to the adjoint trick (back-propagation).
    =&gt; This implementation is not suited for big systems.

    Incremental formulation is used, so the formulae look like the ones in iEnKS.
    &#34;&#34;&#34;
    B: Optional[np.ndarray] = None
    xB: float                = 1.0

    def assimilate(self, HMM, xx, yy):
        Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
        R, KObs = HMM.Obs.noise.C, HMM.t.KObs
        Rm12 = R.sym_sqrt_inv
        Nx = Dyn.M

        # Set background covariance. Note that it is static (compare to iEnKS).
        if self.B in (None, &#39;clim&#39;):
            # Use climatological cov, ...
            B = np.cov(xx.T)  # ... estimated from truth
        elif self.B == &#39;eye&#39;:
            B = np.eye(Nx)
        else:
            B = self.B
        B *= self.xB
        B12 = CovMat(B).sym_sqrt

        # Init
        x = X0.mu
        stats.assess(0, mu=x, Cov=B)

        # Loop over DA windows (DAW).
        for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
            kLag = kObs-self.Lag
            DAW = range(max(0, kLag+1), min(kObs, KObs) + 1)

            # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
            if 0 &lt;= kObs &lt;= KObs:

                # Init iterations.
                w   = np.zeros(Nx)  # Control vector for the mean state.
                x0  = x.copy()     # Increment reference.

                for iteration in np.arange(self.nIter):
                    # Reconstruct smoothed state.
                    x = x0 + B12@w
                    X = B12  # Aggregate composite TLMs onto B12
                    # Forecast.
                    for kCycle in DAW:
                        for k, t, dt in chrono.cycle(kCycle):
                            X = Dyn.linear(x, t-dt, dt) @ X
                            x = Dyn(x, t-dt, dt)

                    # Assess forecast stats
                    if iteration == 0:
                        stats.assess(k, kObs, &#39;f&#39;, mu=x, Cov=X@X.T)

                    # Observe.
                    Y  = Obs.linear(x, t) @ X
                    xo = Obs(x, t)

                    # Analysis prep.
                    y      = yy[kObs]          # Get current obs.
                    dy     = Rm12 @ (y - xo)   # Transform obs space.
                    Y      = Rm12 @ Y          # Transform obs space.
                    V, s, UT = svd0(Y.T)         # Decomp for lin-alg update comps.

                    # Post. cov (approx) of w,
                    # estimated at current iteration, raised to power.
                    Cow1 = (V * (pad0(s**2, Nx) + 1)**-1.0) @ V.T

                    # Compute analysis update.
                    grad = Y.T@dy - w          # Cost function gradient
                    dw   = Cow1@grad           # Gauss-Newton step
                    w   += dw                  # Step

                    if dw@dw &lt; self.wtol*Nx:
                        break
                # END loop iteration

                # Assess (analysis) stats.
                final_increment = X@dw
                stats.assess(k,   kObs, &#39;a&#39;, mu=x+final_increment, Cov=X@Cow1@X.T)
                stats.iters[kObs] = iteration+1

                # Final (smoothed) estimate at [kLag].
                x = x0 + B12@w
                X = B12
            # END assimilation block

            # Slide/shift DAW by propagating smoothed (&#39;s&#39;) state from [kLag].
            if -1 &lt;= kLag &lt; KObs:
                if kLag &gt;= 0:
                    stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, mu=x, Cov=X@Cow1@X.T)
                for k, t, dt in chrono.cycle(kLag+1):
                    stats.assess(k-1, None, &#39;u&#39;, mu=x, Cov=Y@Y.T)
                    X = Dyn.linear(x, t-dt, dt) @ X
                    x = Dyn(x, t-dt, dt)

        # END loop kObs
        stats.assess(k, KObs, &#39;us&#39;, mu=x, Cov=X@Cow1@X.T)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dapper.da_methods.variational.Var4D.B"><code class="name">var <span class="ident">B</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.xB"><code class="name">var <span class="ident">xB</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.Lag"><code class="name">var <span class="ident">Lag</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.nIter"><code class="name">var <span class="ident">nIter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.wtol"><code class="name">var <span class="ident">wtol</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dapper.da_methods.variational.Var4D.da_method"><code class="name">var <span class="ident">da_method</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.da_methods.variational.Var4D.assimilate"><code class="name flex">
<span>def <span class="ident">assimilate</span></span>(<span>self, HMM, xx, yy)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assimilate(self, HMM, xx, yy):
    Dyn, Obs, chrono, X0, stats = HMM.Dyn, HMM.Obs, HMM.t, HMM.X0, self.stats
    R, KObs = HMM.Obs.noise.C, HMM.t.KObs
    Rm12 = R.sym_sqrt_inv
    Nx = Dyn.M

    # Set background covariance. Note that it is static (compare to iEnKS).
    if self.B in (None, &#39;clim&#39;):
        # Use climatological cov, ...
        B = np.cov(xx.T)  # ... estimated from truth
    elif self.B == &#39;eye&#39;:
        B = np.eye(Nx)
    else:
        B = self.B
    B *= self.xB
    B12 = CovMat(B).sym_sqrt

    # Init
    x = X0.mu
    stats.assess(0, mu=x, Cov=B)

    # Loop over DA windows (DAW).
    for kObs in progbar(np.arange(-1, KObs+self.Lag+1)):
        kLag = kObs-self.Lag
        DAW = range(max(0, kLag+1), min(kObs, KObs) + 1)

        # Assimilation (if ∃ &#34;not-fully-assimlated&#34; obs).
        if 0 &lt;= kObs &lt;= KObs:

            # Init iterations.
            w   = np.zeros(Nx)  # Control vector for the mean state.
            x0  = x.copy()     # Increment reference.

            for iteration in np.arange(self.nIter):
                # Reconstruct smoothed state.
                x = x0 + B12@w
                X = B12  # Aggregate composite TLMs onto B12
                # Forecast.
                for kCycle in DAW:
                    for k, t, dt in chrono.cycle(kCycle):
                        X = Dyn.linear(x, t-dt, dt) @ X
                        x = Dyn(x, t-dt, dt)

                # Assess forecast stats
                if iteration == 0:
                    stats.assess(k, kObs, &#39;f&#39;, mu=x, Cov=X@X.T)

                # Observe.
                Y  = Obs.linear(x, t) @ X
                xo = Obs(x, t)

                # Analysis prep.
                y      = yy[kObs]          # Get current obs.
                dy     = Rm12 @ (y - xo)   # Transform obs space.
                Y      = Rm12 @ Y          # Transform obs space.
                V, s, UT = svd0(Y.T)         # Decomp for lin-alg update comps.

                # Post. cov (approx) of w,
                # estimated at current iteration, raised to power.
                Cow1 = (V * (pad0(s**2, Nx) + 1)**-1.0) @ V.T

                # Compute analysis update.
                grad = Y.T@dy - w          # Cost function gradient
                dw   = Cow1@grad           # Gauss-Newton step
                w   += dw                  # Step

                if dw@dw &lt; self.wtol*Nx:
                    break
            # END loop iteration

            # Assess (analysis) stats.
            final_increment = X@dw
            stats.assess(k,   kObs, &#39;a&#39;, mu=x+final_increment, Cov=X@Cow1@X.T)
            stats.iters[kObs] = iteration+1

            # Final (smoothed) estimate at [kLag].
            x = x0 + B12@w
            X = B12
        # END assimilation block

        # Slide/shift DAW by propagating smoothed (&#39;s&#39;) state from [kLag].
        if -1 &lt;= kLag &lt; KObs:
            if kLag &gt;= 0:
                stats.assess(chrono.kkObs[kLag], kLag, &#39;s&#39;, mu=x, Cov=X@Cow1@X.T)
            for k, t, dt in chrono.cycle(kLag+1):
                stats.assess(k-1, None, &#39;u&#39;, mu=x, Cov=Y@Y.T)
                X = Dyn.linear(x, t-dt, dt) @ X
                x = Dyn(x, t-dt, dt)

    # END loop kObs
    stats.assess(k, KObs, &#39;us&#39;, mu=x, Cov=X@Cow1@X.T)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper.da_methods" href="index.html">dapper.da_methods</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.da_methods.variational.iEnKS" href="#dapper.da_methods.variational.iEnKS">iEnKS</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.variational.iEnKS.assimilate" href="#dapper.da_methods.variational.iEnKS.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.upd_a" href="#dapper.da_methods.variational.iEnKS.upd_a">upd_a</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.N" href="#dapper.da_methods.variational.iEnKS.N">N</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.MDA" href="#dapper.da_methods.variational.iEnKS.MDA">MDA</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.step" href="#dapper.da_methods.variational.iEnKS.step">step</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.bundle" href="#dapper.da_methods.variational.iEnKS.bundle">bundle</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.xN" href="#dapper.da_methods.variational.iEnKS.xN">xN</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.infl" href="#dapper.da_methods.variational.iEnKS.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.rot" href="#dapper.da_methods.variational.iEnKS.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.Lag" href="#dapper.da_methods.variational.iEnKS.Lag">Lag</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.nIter" href="#dapper.da_methods.variational.iEnKS.nIter">nIter</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.wtol" href="#dapper.da_methods.variational.iEnKS.wtol">wtol</a></code></li>
<li><code><a title="dapper.da_methods.variational.iEnKS.da_method" href="#dapper.da_methods.variational.iEnKS.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.variational.iLEnKS" href="#dapper.da_methods.variational.iLEnKS">iLEnKS</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.variational.iLEnKS.assimilate" href="#dapper.da_methods.variational.iLEnKS.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.upd_a" href="#dapper.da_methods.variational.iLEnKS.upd_a">upd_a</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.N" href="#dapper.da_methods.variational.iLEnKS.N">N</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.loc_rad" href="#dapper.da_methods.variational.iLEnKS.loc_rad">loc_rad</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.taper" href="#dapper.da_methods.variational.iLEnKS.taper">taper</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.xN" href="#dapper.da_methods.variational.iLEnKS.xN">xN</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.infl" href="#dapper.da_methods.variational.iLEnKS.infl">infl</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.rot" href="#dapper.da_methods.variational.iLEnKS.rot">rot</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.Lag" href="#dapper.da_methods.variational.iLEnKS.Lag">Lag</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.nIter" href="#dapper.da_methods.variational.iLEnKS.nIter">nIter</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.wtol" href="#dapper.da_methods.variational.iLEnKS.wtol">wtol</a></code></li>
<li><code><a title="dapper.da_methods.variational.iLEnKS.da_method" href="#dapper.da_methods.variational.iLEnKS.da_method">da_method</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.da_methods.variational.Var4D" href="#dapper.da_methods.variational.Var4D">Var4D</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.da_methods.variational.Var4D.assimilate" href="#dapper.da_methods.variational.Var4D.assimilate">assimilate</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.B" href="#dapper.da_methods.variational.Var4D.B">B</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.xB" href="#dapper.da_methods.variational.Var4D.xB">xB</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.Lag" href="#dapper.da_methods.variational.Var4D.Lag">Lag</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.nIter" href="#dapper.da_methods.variational.Var4D.nIter">nIter</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.wtol" href="#dapper.da_methods.variational.Var4D.wtol">wtol</a></code></li>
<li><code><a title="dapper.da_methods.variational.Var4D.da_method" href="#dapper.da_methods.variational.Var4D.da_method">da_method</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>